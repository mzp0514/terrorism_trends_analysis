{
    "title": "FACEBOOK TARGETS TERRORISM Social network strengthens effort to stop extremists' propaganda",
    "publisher": "daily news ",
    "year": 2017,
    "month": 6,
    "day": 16,
    "full text": "GETTY IMAGES/ISTOCKPHOTO\nANDY RAIN, EUROPEAN PRESSPHOTO AGENCY Tributes on London Bridge remember Spanish national Ignacio Echeverria, 39, who died in the attack and was hailed as a hero for trying to defend a woman during the June 3 rampage.\nSAN FRANCISCO With attacks on Western targets increasing pressure on Facebook, the giant social network says it's making a new push to crack down on terrorist activity by using sophisticated algorithms to mine words, images and videos to root out and remove extremists' propaganda and messages.\nArtificial intelligence can't do the job alone, so Facebook says it has amassed a team of 150, including counterterrorism experts, who are dedicated to tracking and taking down propaganda and other materials.\nIt's also collaborating with fellow technology companies and consulting with researchers to keep up with the ever-changing social media tactics of the Islamic State and other terror groups.\n\"Just as terrorist propaganda has changed over the years, so have our enforcement efforts. We are now really focused on using technology to find this content so that we can remove it before people are seeing it,\" says Monika Bickert, a former federal prosecutor who runs global policy management, the team that decides what can be posted on Facebook.\n\"We want Facebook to be a very hostile environment for terrorists, and we are doing everything we can to keep terror propaganda off Facebook.\"\nSharp criticism from European officials, advertiser boycotts and lawsuits from family members of people killed in terrorist attacks are pushing Face-book, Google, Microsoft and Twitter to find more effective ways to banish terrorist activity.\nNew video digital fingerprinting technologies called \"hashes\" are helping flag and intercept extremist videos before they are posted. But these new tools can't yet keep terrorists from gathering on Facebook to recruit and communicate with followers.\nIn the wake of the London attacks, British Prime Minister Theresa May has accused Face-book and other companies of not doing enough to crack down on terrorist activity. This week, May said she and French President Emmanuel Macron were working on a plan that would make Internet companies legally liable for extremist materials on their services.\n\"They want to hear that social media companies are taking this seriously. We are taking it seriously,\" Bickert said. \"The measures they are talking about, we are already doing.\"\nFor years Facebook balanced the threat to free speech with its ongoing efforts to eradicate terrorist propaganda.\nAbout a year ago, it intensified efforts to combat terrorism, resulting in the removal of a great deal of that activity from its platform, says Seamus Hughes, deputy director of the program on extremism at George Washington University.\n\"Facebook at some point in the last year planted a flag in the ground and said: Not on our platform,\" Hughes said.\nEven as Facebook makes progress on one terrain, new battlefields emerge.\nResearchers such as Hughes say much of the terrorist activity that has left Facebook has migrated to encrypted messaging services such as Telegram and Facebook-owned WhatsApp.\nFacebook Live, the real-time streaming service, also presents a new challenge. And terrorists are still lurking out of sight on Face-book in private groups.\nArtificial intelligence is already improving the ability to stop the spread of terrorist content on Facebook, such as flagging and intercepting known terrorist videos before they can be uploaded, says Brian Fishman, lead policy manager for counterterrorism at Facebook and the author of The Master Plan: ISIS, al-Qaeda, and the Jihadi Strategy for Final Victory.\nArtificial intelligence is also being used to analyze text that has been removed for supporting or praising terrorist organizations such as the Islamic State and al-Qaeda as well as their affiliates to detect other content that may be terrorist propaganda.\nThat same technology is being used to ferret out private groups that support terrorism.\nFacebook says it finds more than half of accounts are removed from the social network for terrorist activity.\nBut artificial intelligence has its limits, making human intervention necessary, for example, to distinguish between an image in a news article about terrorism and terrorism propaganda, so Face-book relies on content moderators.\n\"There is no switch you can flip. There is no 'Find the Terrorist' button,\" Fishman said.\nAs in the offline world, terrorists tend to operate in clusters, so it identifies pages, groups, posts or profiles supporting terrorism to identify other accounts and content that support terrorism.\nFacebook is also getting better at keeping these terrorists and their sympathizers from setting up new fake accounts so that it is not engaged in an endless game of Whac-a-Mole as terrorists create accounts as quickly as they can be deleted, he said.\n\nLoad-Date: June 16, 2017"
}